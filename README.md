# Infrared-image-enhancement-

ğŸ”¥ Infrared Image Enhancement using UNet-Res-CBAM
ğŸ“Œ Overview

Infrared (IR) images often suffer from low contrast, blur, noise, and poor structural visibility due to sensor limitations and environmental factors.
This project proposes a deep learningâ€“based infrared image enhancement pipeline using a Residual UNet architecture augmented with CBAM attention to improve clarity while preserving thermal structure.

The entire pipeline is implemented as a single, modular script supporting dataset preparation, training, checkpoint recovery, and evaluation.

ğŸ§  Key Highlights

Residual UNet architecture for stable training and feature preservation

CBAM (Channel + Spatial Attention) for adaptive feature enhancement

Synthetic degradation pipeline for supervised learning

Fully reproducible end-to-end workflow

Google Driveâ€“safe checkpoints and outputs

ğŸ—ï¸ Model Architecture
ğŸ”¹ Backbone

UNet encoderâ€“decoder structure

Skip connections for spatial detail preservation

Residual convolution blocks for improved gradient flow

ğŸ”¹ Attention Mechanism (CBAM)

Channel Attention â†’ emphasizes informative feature maps

Spatial Attention â†’ focuses on salient regions in IR images

Applied at multiple decoder stages

ğŸ”¹ Final Output

3-channel enhanced IR image

Sigmoid activation for stable intensity mapping

Input IR â†’ Encoder â†’ Bottleneck â†’ Decoder + CBAM â†’ Enhanced IR

ğŸ“‚ Project Structure
IR_Project/
â”‚
â”œâ”€â”€ original_images/
â”‚   â””â”€â”€ sober/                 # Clean infrared images
â”‚
â”œâ”€â”€ degraded_images/           # Synthetic degraded IR images
â”‚
â”œâ”€â”€ patches/
â”‚   â”œâ”€â”€ input/                 # Degraded patches (patch_XXXXXX.png)
â”‚   â””â”€â”€ gt/                    # Ground-truth patches
â”‚
â”œâ”€â”€ checkpoints/
â”‚   â””â”€â”€ best.pth               # Best validation model
â”‚
â”œâ”€â”€ results/
â”‚   â””â”€â”€ *_grid.png              # Input | Output | GT comparisons
â”‚
â”œâ”€â”€ final_pipeline.py           # End-to-end pipeline
â””â”€â”€ README.md

ğŸ§ª Dataset Preparation

Since large paired IR datasets are scarce, the project uses synthetic degradation:

Degradation operations

Downsampling & upsampling

Gaussian noise

Gaussian blur

Contrast compression

Patch extraction

Patch size: 384 Ã— 384

Patches per image: 6

Automatically paired as patch_000001.png

âš™ï¸ Pipeline Modes

The pipeline is controlled via a single variable:

MODE = "prepare"   # prepare | repair | train | eval

ğŸ”¹ Prepare Dataset
MODE = "prepare"


Generates degraded images

Extracts aligned inputâ€“GT patches

ğŸ”¹ Train Model
MODE = "train"


Automatically resumes from best checkpoint

Saves best model to Google Drive

Loss function:

0.7 Ã— L1 + 0.3 Ã— MSE + 0.1 Ã— (1 âˆ’ SSIM)

ğŸ”¹ Evaluate
MODE = "eval"


Saves side-by-side grids:

[Input | Enhanced | Ground Truth]

ğŸ“Š Image Quality Metrics
Metric	Value
PSNR	30.38 dB
SSIM	0.968
Entropy (Input)	6.42
Entropy (Output)	6.61
ğŸ” Interpretation

High PSNR â†’ strong reconstruction accuracy

SSIM â‰ˆ 0.97 â†’ excellent structural preservation

Entropy increase â†’ richer texture and information content

ğŸ–¼ï¸ Sample Results
Degraded Input	Enhanced Output	Ground Truth

		

(Replace with your generated grids)

ğŸ› ï¸ Technologies Used

Language: Python

Deep Learning: PyTorch

Vision: OpenCV, PIL

Training: AdamW optimizer

Environment: Google Colab + Google Drive

ğŸ¯ Applications

Night-vision enhancement

Thermal surveillance

Autonomous navigation

Industrial inspection

Defense & security imaging

ğŸš€ Future Improvements

Transformer-based IR enhancement

Real-time inference optimization

Multi-spectral fusion (IR + RGB)

Human perceptual evaluation studies
